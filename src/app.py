import streamlit as st
import cv2
import numpy as np
import tempfile
import os
import time
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

from face_detector import FaceDetector
from emotion_classifier import EmotionClassifier
from quality_analyzer import QualityAnalyzer
from metrics_collector import MetricsCollector
from analytics_manager import AnalyticsManager

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Real-time Video Analytics", 
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ“¹ Real-time Video Quality Analysis & Face Emotion Detection")

# ì´ˆê¸°í™” í•¨ìˆ˜ë“¤
@st.cache_resource
def load_models():
    """ëª¨ë“  ëª¨ë¸ê³¼ ë¶„ì„ê¸° ë¡œë“œ"""
    try:
        face_detector = FaceDetector()
        emotion_classifier = EmotionClassifier()
        quality_analyzer = QualityAnalyzer()
        return face_detector, emotion_classifier, quality_analyzer
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None, None

# ëª¨ë¸ ë¡œë“œ
face_detector, emotion_classifier, quality_analyzer = load_models()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'running' not in st.session_state:
    st.session_state.running = False
if 'metrics_history' not in st.session_state:
    st.session_state.metrics_history = []
if 'quality_history' not in st.session_state:
    st.session_state.quality_history = []

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title("âš™ï¸ ì„¤ì •")

# ë¶„ì„ ì˜µì…˜
st.sidebar.subheader("ğŸ“Š ë¶„ì„ ì˜µì…˜")
enable_face = st.sidebar.checkbox("ì–¼êµ´ ê²€ì¶œ", value=True)
enable_emotion = st.sidebar.checkbox("ê°ì • ë¶„ì„", value=True)
enable_quality = st.sidebar.checkbox("í’ˆì§ˆ ë¶„ì„", value=True)
enable_mlflow = st.sidebar.checkbox("MLflow ë¡œê¹…", value=False)

# ë¹„ë””ì˜¤ ì†ŒìŠ¤
st.sidebar.subheader("ğŸ“¹ ë¹„ë””ì˜¤ ì†ŒìŠ¤")
source_type = st.sidebar.radio("ì†ŒìŠ¤ ì„ íƒ", ["ì›¹ìº ", "ì˜ìƒ íŒŒì¼", "ìœ íŠœë¸Œ ë§í¬"])

video_source = None
temp_file_path = None

if source_type == "ì›¹ìº ":
    video_source = 0
    st.sidebar.info("ğŸ’¡ ì›¹ìº  ì‚¬ìš© ì¤‘")
elif source_type == "ì˜ìƒ íŒŒì¼":
    uploaded_file = st.sidebar.file_uploader(
        "ì˜ìƒ ì—…ë¡œë“œ", 
        type=["mp4", "avi", "mov", "mkv"]
    )
    if uploaded_file:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(uploaded_file.read())
        temp_file_path = tfile.name
        video_source = temp_file_path
        st.sidebar.success(f"âœ… {uploaded_file.name}")
elif source_type == "ìœ íŠœë¸Œ ë§í¬":
    youtube_url = st.sidebar.text_input(
        "ìœ íŠœë¸Œ URL ì…ë ¥",
        placeholder="https://www.youtube.com/watch?v=..."
    )
    
    if youtube_url:
        st.sidebar.info("ğŸ’¡ ìœ íŠœë¸Œ ì˜ìƒ ë¡œë“œ ì¤‘...")
        try:
            import yt_dlp
            
            ydl_opts = {
                "quiet": True,
                "format": "best[ext=mp4]/best"
            }
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(youtube_url, download=False)
                video_source = info["url"]
                
            st.sidebar.success("âœ… ìœ íŠœë¸Œ ì˜ìƒ ë¡œë“œ ì™„ë£Œ")
        except ImportError:
            st.sidebar.error("âŒ yt-dlp ì„¤ì¹˜ í•„ìš”: pip install yt-dlp")
        except Exception as e:
            st.sidebar.error(f"âŒ ìœ íŠœë¸Œ ë¡œë“œ ì‹¤íŒ¨: {e}")

# FPS ì œí•œ
fps_limit = st.sidebar.slider("FPS ì œí•œ", 1, 30, 15)

# í’ˆì§ˆ ì„ê³„ê°’
quality_threshold = st.sidebar.slider("í’ˆì§ˆ ì„ê³„ê°’", 0.0, 1.0, 0.6, 0.1)

# ë©”ì¸ ë ˆì´ì•„ì›ƒ
col1, col2, col3 = st.columns([2, 1, 1])

with col1:
    st.subheader("ğŸ¥ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼")
    video_placeholder = st.empty()

with col2:
    st.subheader("ğŸ“ˆ ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­")
    metrics_placeholder = st.empty()

with col3:
    st.subheader("ğŸ’­ ê°ì • ë¶„ì„")
    emotion_placeholder = st.empty()

# í’ˆì§ˆ ê·¸ë˜í”„
st.subheader("ğŸ“Š í’ˆì§ˆ ì¶”ì´")
quality_chart_placeholder = st.empty()

# ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
system_metrics_placeholder = st.empty()

# ì»¨íŠ¸ë¡¤ ë²„íŠ¼
control_col1, control_col2, control_col3 = st.columns([1, 1, 4])
with control_col1:
    if st.button("â–¶ï¸ ì‹œì‘", type="primary"):
        st.session_state.running = True
        st.session_state.metrics_history = []
        st.session_state.quality_history = []

with control_col2:
    if st.button("â¹ï¸ ì •ì§€"):
        st.session_state.running = False

with control_col3:
    if st.button("ğŸ—‘ï¸ ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.metrics_history = []
        st.session_state.quality_history = []

# ë©”ì¸ ì²˜ë¦¬ ë£¨í”„
if st.session_state.running and video_source is not None:
    cap = cv2.VideoCapture(video_source)
    
    if not cap.isOpened():
        st.error("âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        st.session_state.running = False
    else:
        # ë§¤ë‹ˆì € ì´ˆê¸°í™”
        metrics_collector = MetricsCollector()
        analytics_manager = AnalyticsManager() if enable_mlflow else None
        
        # MLflow ì‹¤í–‰ ì‹œì‘
        if analytics_manager:
            analytics_manager.start_run()
        
        frame_count = 0
        skip_frames = max(1, 30 // fps_limit)  # í”„ë ˆì„ ìŠ¤í‚µ ê³„ì‚°
        analysis_interval = 5  # 5í”„ë ˆì„ë§ˆë‹¤ ë¶„ì„
        
        while st.session_state.running:
            ret, frame = cap.read()
            if not ret:
                st.info("ğŸ¬ ì˜ìƒ ì¢…ë£Œ")
                break
            
            # í”„ë ˆì„ ìŠ¤í‚µ (FPS ì¡°ì ˆ)
            if frame_count % skip_frames != 0:
                frame_count += 1
                continue
            
            # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ì€ í•­ìƒ ìˆ˜ì§‘
            sys_metrics = metrics_collector.get_all_metrics()
            
            # ë¬´ê±°ìš´ ë¶„ì„ì€ ì¼ì • ê°„ê²©ìœ¼ë¡œë§Œ
            should_analyze = (frame_count % analysis_interval == 0)
            
            # í’ˆì§ˆ ë¶„ì„ (ê°„ê²©ë§ˆë‹¤)
            quality_results = None
            if enable_quality and quality_analyzer and should_analyze:
                quality_results = quality_analyzer.analyze_frame(frame)
                st.session_state.quality_history.append(quality_results['quality_score'])
                
                # í’ˆì§ˆ ì •ë³´ ì˜¤ë²„ë ˆì´
                if quality_results:
                    quality_text = f"Quality: {quality_results['quality_status']} ({quality_results['quality_score']:.2f})"
                    color = (0, 255, 0) if quality_results['quality_score'] > quality_threshold else (0, 0, 255)
                    cv2.putText(frame, quality_text, (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            
            # ì–¼êµ´ ê²€ì¶œ ë° ê°ì • ë¶„ì„ (ê°„ê²©ë§ˆë‹¤)
            if enable_face and face_detector and should_analyze:
                faces = face_detector.detect_faces(frame)
                
                if enable_emotion and emotion_classifier and len(faces) > 0:
                    emotions_data = []
                    for i, (x, y, w, h) in enumerate(faces):
                        # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
                        face_roi = frame[y:y+h, x:x+w]
                        
                        # ê°ì • ì˜ˆì¸¡
                        emotion, confidence = emotion_classifier.predict_emotion(face_roi)
                        emotions_data.append({
                            'face_id': i,
                            'emotion': emotion,
                            'confidence': confidence
                        })
                        
                        # í”„ë ˆì„ì— ê·¸ë¦¬ê¸°
                        frame = emotion_classifier.draw_emotion(
                            frame, (x, y, w, h), emotion, confidence
                        )
                        
                        # MLflow ë¡œê¹…
                        if analytics_manager:
                            analytics_manager.log_emotion(emotion, confidence, i)
                    
                    # ê°ì • í‘œì‹œ
                    with emotion_placeholder.container():
                        for data in emotions_data:
                            st.write(f"Face {data['face_id']}: **{data['emotion']}** ({data['confidence']:.2%})")
                else:
                    # ì–¼êµ´ë§Œ ê·¸ë¦¬ê¸°
                    frame = face_detector.draw_faces(frame, faces)
            
            # FPS ì •ë³´ ì¶”ê°€
            cv2.putText(frame, f"FPS: {sys_metrics['current_fps']:.1f}", (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # ë¹„ë””ì˜¤ í‘œì‹œ
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            video_placeholder.image(frame_rgb, channels="RGB", use_column_width=True)
            
            # ë©”íŠ¸ë¦­ í‘œì‹œ
            with metrics_placeholder.container():
                st.metric("FPS", f"{sys_metrics['current_fps']:.1f}")
                st.metric("CPU", f"{sys_metrics['cpu_percent']:.1f}%")
                st.metric("Memory", f"{sys_metrics['memory_percent']:.1f}%")
                if quality_results:
                    st.metric("í’ˆì§ˆ ì ìˆ˜", f"{quality_results['quality_score']:.2f}")
            
            # í’ˆì§ˆ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸ (30í”„ë ˆì„ë§ˆë‹¤)
            if len(st.session_state.quality_history) > 0 and frame_count % 30 == 0:
                with quality_chart_placeholder.container():
                    fig, ax = plt.subplots(figsize=(10, 3))
                    ax.plot(st.session_state.quality_history[-100:], color='blue', linewidth=2)
                    ax.axhline(y=quality_threshold, color='r', linestyle='--', label=f'Threshold: {quality_threshold}')
                    ax.set_ylabel('Quality Score')
                    ax.set_xlabel('Frame')
                    ax.set_ylim([0, 1])
                    ax.legend()
                    ax.grid(True, alpha=0.3)
                    st.pyplot(fig)
                    plt.close()
            
            # MLflow ë¡œê¹…
            if analytics_manager and frame_count % 10 == 0:
                log_data = sys_metrics.copy()
                if quality_results:
                    log_data.update(quality_results)
                analytics_manager.log_metrics(log_data, step=frame_count)
            
            frame_count += 1
        
        # ì •ë¦¬
        cap.release()
        if analytics_manager:
            analytics_manager.end_run()
        
        # ìµœì¢… í†µê³„
        with system_metrics_placeholder.container():
            st.success("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("ì´ í”„ë ˆì„", frame_count)
            col2.metric("í‰ê·  FPS", f"{sys_metrics.get('avg_fps', 0):.1f}")
            if st.session_state.quality_history:
                col3.metric("í‰ê·  í’ˆì§ˆ", f"{np.mean(st.session_state.quality_history):.2f}")
                col4.metric("ìµœì € í’ˆì§ˆ", f"{np.min(st.session_state.quality_history):.2f}")

# í•˜ë‹¨ ì •ë³´
st.divider()
st.info("ğŸ’¡ Docker + MLflow + PyTorch ê¸°ë°˜ ì‹¤ì‹œê°„ ì˜ìƒ ë¶„ì„(ê°ì •/í’ˆì§ˆ/OCR/ì˜ˆì¸¡) í†µí•© ì‹œìŠ¤í…œ")

# ì„ì‹œ íŒŒì¼ ì •ë¦¬
if temp_file_path and os.path.exists(temp_file_path):
    try:
        os.unlink(temp_file_path)
    except:
        pass